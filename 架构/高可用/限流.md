## 限流
限流的分类：
* 合法性验证限流：比如验证码、IP黑名单等，这些手段可以有效的防止恶意攻击和爬虫采集；
* 容器限流：比如 Tomcat、Nginx 等限流手段，其中 Tomcat 可以设置最大线程数（maxThreads），当并发超过最大线程数会排队等待执行；而 Nginx 提供了两种限流手段：一是控制速率，二是控制并发连接数；
* 服务端限流：比如我们在服务器端通过限流算法实现限流，此项也是我们本文介绍的重点。

限流的方式分类
* 熔断
* 降级

## 一、容器限流
### 1、Tomcat 限流
Tomcat 8.5 版本的最大线程数在 conf/server.xml 配置中，如下所示：

```
<Connector port="8080" protocol="HTTP/1.1"
          connectionTimeout="20000"
          maxThreads="150"
          redirectPort="8443" />
```
其中 maxThreads 就是 Tomcat 的最大线程数，当请求的并发大于此值（maxThreads）时，请求就会排队执行，这样就完成了限流的目的。

小贴士：maxThreads 的值可以适当的调大一些，此值默认为 150（Tomcat 版本 8.5.42），但这个值也不是越大越好，要看具体的硬件配置，需要注意的是每开启一个线程需要耗用 1MB 的 JVM 内存空间用于作为线程栈之用，并且线程越多 GC 的负担也越重。最后需要注意一下，操作系统对于进程中的线程数有一定的限制，Windows 每个进程中的线程数不允许超过 2000，Linux 每个进程中的线程数不允许超过 1000。

### 2、Nginx 限流
Nginx 提供了两种限流手段：一是控制速率，二是控制并发连接数。

##### 2.1 控制速率
我们需要使用 limit_req_zone 用来限制单位时间内的请求数，即速率限制，示例配置如下：

```
limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s;
server { 
    location / { 
        limit_req zone=mylimit;
    }
}
```
以上配置表示，限制每个 IP 访问的速度为 2r/s，因为 Nginx 的限流统计是基于毫秒的，我们设置的速度是 2r/s，转换一下就是 500ms 内单个 IP 只允许通过 1 个请求，从 501ms 开始才允许通过第 2 个请求。

上面的速率控制虽然很精准但是应用于真实环境未免太苛刻了，真实情况下我们应该控制一个 IP 单位总时间内的总访问次数，而不是像上面那么精确但毫秒，我们可以使用 burst 关键字开启此设置，示例配置如下：

```
limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s;
server { 
    location / { 
     limit_req zone=mylimit burst=4;
    }
}
```
burst=4 表示每个 IP 最多允许4个突发请求，

##### 2.2 控制并发数
利用 limit_conn_zone 和 limit_conn 两个指令即可控制并发数，示例配置如下：

```
limit_conn_zone $binary_remote_addr zone=perip:10m;
limit_conn_zone $server_name zone=perserver:10m;
server {
    ...
    limit_conn perip 10;
    limit_conn perserver 100;
}
```
其中 limit_conn perip 10 表示限制单个 IP 同时最多能持有 10 个连接；limit_conn perserver 100 表示 server 同时能处理并发连接的总数为 100 个。

小贴士：只有当 request header 被后端处理后，这个连接才进行计数。

## 二、服务端限流
服务端限流需要配合限流的算法来执行，而算法相当于执行限流的“大脑”，用于指导限制方案的实现。

限流的常见用的实现算法有以下四种：
* 计数器（固定窗口）算法
* 时间窗口算法
* 漏桶算法
* 令牌算法

### 1、计数器（固定窗口）算法
计数器算法是使用计数器在周期内累加访问次数，当达到设定的限流值时，触发限流策略。下一个周期开始时，进行清零，重新计数。

此算法在单机还是分布式环境下实现都非常简单，**使用redis的incr原子自增性和线程安全即可轻松实现。**

这个算法通常用于QPS限流和统计总访问量，对于秒级以上的时间周期来说，会存在一个非常严重的问题，那就是临界问题，

假设1min内服务器的负载能力为100，因此一个周期的访问量限制在100，然而在第一个周期的最后5秒和下一个周期的开始5秒时间段内，分别涌入100的访问量，虽然没有超过每个周期的限制量，但是整体上10秒内已达到200的访问量，已远远超过服务器的负载能力，由此可见，计数器算法方式限流对于周期比较长的限流，存在很大的弊端。
 
### 2、时间窗口算法(滑动时间算法)
所谓的滑动时间算法指的是以当前时间为截止时间，往前取一定的时间，比如往前取 60s 的时间，在这 60s 之内运行最大的访问数为 100，此时算法的执行逻辑为，先清除 60s 之前的所有请求记录，再计算当前集合内请求数量是否大于设定的最大请求数 100，如果大于则执行限流拒绝策略，否则插入本次请求记录并返回可以正常执行的标识给客户端。

我们可以**借助 Redis 的有序集合 ZSet 来实现时间窗口算法限流，**实现的过程是先使用 ZSet 的 key 存储限流的 ID，score 用来存储请求的时间，每次有请求访问来了之后，先清空之前时间窗口的访问量，统计现在时间窗口的个数和最大允许访问量对比，如果大于等于最大访问量则返回 false 执行限流操作，否则允许执行业务逻辑，并且在 ZSet 中添加一条有效的访问记录。

优点：
* 当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。
* 此算法可以很好的解决固定窗口算法的临界问题。

此实现方式存在的缺点有3个：
* 使用 ZSet 存储有每次的访问记录，如果数据量比较大时会占用大量的空间，比如 60s 允许 100W 访问时；
* 此代码的执行非原子操作，先判断后增加，中间空隙可穿插其他业务逻辑的执行，最终导致结果不准确。
* 在一定范围内，比如 60s 内只能有 10 个请求，当第一秒时就到达了 10 个请求，那么剩下的 59s 只能把所有的请求都给拒绝掉。

### 3、漏桶算法
而漏桶算法可以解决时间窗口算法的速率不均匀问题。

大致原理类似如下
![20190716090944456.png](https://pic.imgdb.cn/item/625d6d93239250f7c5b79927.png)

漏洞算法的实现步骤是，先声明一个队列用来保存请求，这个队列相当于漏斗，当队列容量满了之后就放弃新来的请求。然后重新声明一个线程定期从任务队列中获取一个或多个任务进行执行，这样就实现了漏桶算法。

我们可以使用 Redis 4.0 版本中提供的 `Redis-Cell模块`，该模块使用的是漏斗算法，并且提供了原子的限流指令，而且依靠 Redis 这个天生的分布式程序就可以实现比较完美的限流了。
 
使用 Redis-Cell 的是`分布式的限流`方案。

### 4、令牌算法
令牌桶算法是程序以r（r=时间周期/限流值）的速度向令牌桶中增加令牌，直到令牌桶满，请求到达时向令牌桶请求令牌，如获取到令牌则通过请求，否则触发限流策略

![20190716090944463.png](https://pic.imgdb.cn/item/625d6e1e239250f7c5b9025c.png)

可以使用 Google 开源的 guava 包，很方便的实现令牌桶算法。

使用 guava 实现的令牌算法属于`程序级别的单机限流`方案。

## 三、各个算法比较

| 算法  | 确定参数 | 空间复杂度 |  时间复杂度| 限制突发流量 |平滑限流 | 分布式环境下实现难度  |
|  ----  | ----  |----  |----  |----  |----  |----  |
| 固定窗口 | 计数周期T、周期内最大访问数N| 低O(1)（记录周期内访问次数及周期开始时间）  | 低O(1)|否| 否 | 低|
| 滑动窗口 | 计数周期T、周期内最大访问数N |高O(N)记录每个小周期中的访问数量）  | 中O(N)|是  | 相对实现。滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑| 中|
|漏桶| 漏桶流出速度r、漏桶容量N  | 低O(1)（记录当前漏桶中容量） | 高O(N) | 是 |是  | 高 | 
| 令牌桶 | 令牌产生速度r、令牌桶容量N | 低O(1)（记录当前令牌桶中令牌数）| 高O(N) |是  | 是 | 高 |


## 四、相关wiki
* 10张图带你彻底搞懂限流、熔断、服务降级 https://baijiahao.baidu.com/s?id=1714316170925203681&wfr=spider&for=pc todo







