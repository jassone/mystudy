## 多级缓存的分层架构

## 一、原则
缓存的设计先后顺序应该是先近到远，先快后慢逐级访问。

缓存的请求顺序是：**用户请求 → HTTP 缓存 → CDN 缓存 → 代理服务器缓存 → 进程内缓存 → 分布式缓存 → 数据库**。

## 二、缓存分类
### 1、 HTTP缓存
如果对每次 HTTP 请求进行缓存，那么可以减少应用服务器的压力。

一般信息的传递通过 HTTP 请求头 Header 来传递。目前比较常见的缓存方式有两种，分别是：

强制缓存：
* Expires 和 Cache-Control

对比缓存：
* Last-Modified/If-Modified-Since 
* ETag / If-None-Match

### 2、CDN 缓存
如果在客户端和服务器之间再加上一层 CDN，可以让 CDN 为应用服务器提供缓存，如果在 CDN 上缓存，就不用再请求应用服务器了。并且 HTTP 缓存提到的两种策略同样可以在 CDN 服务器执行。

CDN 的全称是 Content Delivery Network，即内容分发网络。

让我们来看看它是如何工作的吧：
* 客户端发送 URL 给 DNS 服务器。
* DNS 通过域名解析，把请求指向 CDN 网络中的 DNS 负载均衡器。
* DNS 负载均衡器将最近 CDN 节点的 IP 告诉 DNS，DNS 告之客户端最新 CDN 节点的 IP。
* 客户端请求最近的 CDN 节点。
* CDN 节点从应用服务器获取资源返回给客户端，同时将静态信息缓存。注意：客户端下次互动的对象就是 CDN 缓存了，CDN 可以和应用服务器同步缓存信息。
* CDN 接受客户端的请求，它就是离客户端最近的服务器，它后面会链接多台服务器，起到了缓存和负载均衡的作用。

### 3、负载均衡缓存
在到达应用服务之前，请求还要经过负载均衡器。

虽说它的主要工作是对应用服务器进行负载均衡，但是它也可以作缓存。可以把一些修改频率不高的数据缓存在这里，例如：用户信息，配置信息。通过服务定期刷新这个缓存就行了。

以 Nginx 为例，我们看看它是如何工作的：
* 用户请求在达到应用服务器之前，会先访问 Nginx 负载均衡器，如果发现有缓存信息，直接返回给用户。
* 如果没有发现缓存信息，Nginx 回源到应用服务器获取信息。

另外，有一个缓存更新服务，定期把应用服务器中相对稳定的信息更新到 Nginx 本地缓存中。

### 4、进程内缓存-本地缓存
进程内缓存又叫托管堆缓存，以 Java 为例，这部分缓存放在 JVM 的托管堆上面，同时会受到托管堆回收算法的影响。

由于其运行在内存中，对数据的响应速度很快，通常我们会把热点数据放在这里。

缺点是缓存的空间不能太大，对垃圾回收器的性能有影响。

目前比较流行的实现有 **Ehcache(java)**、GuavaCache、Caffeine。这些架构可以很方便的把一些热点数据放到进程内的缓存中。

这里我们需要关注几个缓存的回收策略，具体的实现架构的回收策略会有所不同，但大致的思路都是一致的：

* FIFO（First In First Out）：先进先出算法，最先放入缓存的数据最先被移除。
* LRU（Least Recently Used）：最近最少使用算法，把最久没有使用过的数据移除缓存。
* LFU（Least Frequently Used）：最不常用算法，在一段时间内使用频率最小的数据被移除缓存。

在分布式架构的今天，多应用中如果采用进程内缓存会存在数据一致性的问题。

这里推荐两个方案：
* 消息队列修改方案-主动更新
应用在修改完自身缓存数据和数据库数据之后，给消息队列发送数据变化通知，其他应用订阅了消息通知，在收到通知的时候修改缓存数据。

* Timer 修改方案-被动更新
为了避免耦合，降低复杂性，对“实时一致性”不敏感的情况下。每个应用都会启动一个 Timer，定时从数据库拉取最新的数据，更新缓存。

不过在有的应用更新数据库后，其他节点通过 Timer 获取数据之间，会读到脏数据。这里需要控制好 Timer 的频率，以及应用与对实时性要求不高的场景。

**特别注意：被动更新时，务必要保证只有一个线程在执行操作，从而避免缓存失效瞬间大量的请求去捞取数据导致雪崩。**

##### 进程内缓存有哪些使用场景呢？
* 场景一：只读数据，可以考虑在进程启动时加载到内存。当然，把数据加载到类似 Redis 这样的进程外缓存服务也能解决这类问题。

* 场景二：高并发，可以考虑使用进程内缓存，例如：秒杀。

### 5、分布式缓存
说完进程内缓存，自然就过度到进程外缓存了。与进程内缓存不同，进程外缓存在应用运行的进程之外，它拥有更大的缓存容量，并且可以部署到不同的物理节点，通常会用分布式缓存的方式实现。

分布式缓存是与应用分离的缓存服务，最大的特点是，自身是一个独立的应用/服务，与本地应用隔离，多个应用可直接共享一个或者多个缓存应用/服务。

既然是分布式缓存，缓存的数据会分布到不同的缓存节点上，每个缓存节点缓存的数据大小通常也是有限制的。

数据被缓存到不同的节点，为了能方便的访问这些节点，需要引入缓存代理，类似 `Twemproxy`。他会帮助请求找到对应的缓存节点。

## 三、nginx本地缓存+redis分布式缓存+tomcat堆缓存的多级缓存架构
##### nginx本地缓存
**抗的是热数据的高并发访问**，一般来说，商品的购买总是有热点的，比如每天购买iphone、nike等知名品牌的东西的人，总是比较多的。

这些热数据，利用nginx本地缓存，由于经常被访问，所以可以被锁定在nginx的本地缓存内

大量的热数据的访问，就是经常会访问的那些数据，就会被保留在nginx本地缓存内，那么对这些热数据的大量访问，就直接走nginx就可以了

那么大量的访问，直接就可以走到nginx就行了，不需要走后续的各种网络开销了。

##### redis分布式大规模缓存
**抗的是很高的离散访问**，支撑海量的数据，高并发的访问，高可用的服务。

redis缓存最大量的数据，最完整的数据和缓存；nginx本地内存有限，也就能cache住部分热数据，除了各种iphone、nike等热数据，其他相对不那么热的数据，可能流量会经常走到redis那里，redis可以做到全量数据的缓存，并且可以通过水平扩展利用redis cluster的多master写入提升并发、高可用的能力。

##### tomcat jvm堆内存缓存
**主要是抗redis大规模灾难的**，如果redis出现了大规模的宕机，导致nginx大量流量直接涌入数据生产服务，那么最后的tomcat堆内存缓存至少可以再抗一下，不至于让数据库直接裸奔

同时tomcat jvm堆内存缓存，也可以抗住redis没有cache住的最后那少量的部分缓存

 

 

 

 