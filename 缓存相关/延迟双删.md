## 延时双删
从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。
因为写和读是并发的，没法保证顺序,就会出现缓存和数据库的数据不一致的问题。是更新缓存呢，还是删除缓存？又或者是先删除缓存，再更新数据库？

## 一、缓存更新策略
### 1 先更新数据库，再更新缓存

##### 弊端一、线程安全角度
同时有请求A和请求B进行更新操作，那么会出现：
* 线程A更新了数据库；
* 线程B更新了数据库；
* 线程B更新了缓存；
* 线程A更新了缓存；

这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑！

##### 弊端二、业务场景角度
有如下两点：
* 如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。
* 如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。

### 2 先删除缓存，再更新数据库
该方案会导致不一致的原因是：同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:
* 请求A进行写操作，删除缓存；
* 请求B查询发现缓存不存在；
* 请求B去数据库查询得到旧值；
* 请求B将旧值写入缓存；
* 请求A将新值写入数据库；

上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。

### 3 先更新数据库，再删除缓存
假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生：
1. 缓存刚好失效；
2. 请求A查询数据库，得一个旧值；
3. 请求B将新值写入数据库；
4. 请求B删除缓存；
5. 请求A将查到的旧值写入缓存；

如果发生上述情况，确实是会发生脏数据。然而，发生这种情况的概率又有多少呢？

发生上述情况有一个先天性条件，就是步骤3的写数据库操作比步骤2的读数据库操作耗时更短，才有可能使得步骤4先于步骤5。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤3耗时比步骤2更短，这一情形很难出现。

## 二、延时双删策略流程

1. 先淘汰缓存；
2. 再写数据库（这两步和原来一样）；
3. 休眠500ms，再次淘汰缓存；

这么做，可以将500ms内所造成的缓存脏数据，再次删除！

### 1、是否还有不一致的情况？有的
![20211225152500.jpg](https://pic.imgdb.cn/item/61c6c7802ab3f51d9194d248.jpg)
但是这种情况比较极端，因为一般查写缓存要比写数据库要快很多。

![20211225153141.jpg](https://pic.imgdb.cn/item/61c6c8ea2ab3f51d91959a55.jpg)


### 2、那么，这个500ms怎么确定的，具体该休眠多久呢？
针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在`读数据业务逻辑的耗时基础上，加几百ms即可`。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

### 3、如果你用了MySQL的读写分离架构怎么办？

在这种情况下，造成数据不一致的原因如下，还是两个请求，一个请求A进行更新操作，另一个请求B进行查询操作。

1. 请求A进行写操作，删除缓存；
2. 请求A将数据写入数据库了；
3. 请求B查询缓存发现，缓存没有值；
4. 请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值；
5. 请求B将旧值写入缓存；
6. 数据库完成主从同步，从库变为新值；

上述情形，就是数据不一致的原因。还是使用双删延时策略。只是，睡眠时间修改为**在主从同步的延时时间基础上，加几百ms。**

### 4、采用这种同步淘汰策略，吞吐量降低怎么办？

那就将第二次删除作为异步的。自己起一个线程，异步删除。这样，写的请求就不用沉睡一段时间后再返回。这么做，加大吞吐量。

### 5、第二次删除，如果删除失败怎么办？

因为第二次删除失败，就会出现如下情形。还是有两个请求，一个请求A进行更新操作，另一个请求B进行查询操作，为了方便，假设是单库：

1. 请求A进行写操作，删除缓存；
2. 请求B查询发现缓存不存在；
3. 请求B去数据库查询得到旧值；
4. 请求B将旧值写入缓存；
5. 请求A将新值写入数据库；
6. 请求A试图去删除请求B写入对缓存值，结果失败了；ok,这也就是说。如果第二次删除缓存失败，会再次出现缓存和数据库不一致的问题。

##### 保障的重试机制
方案一
1. 更新数据库数据；
2. 缓存因为某种问题删除失败；
3. 将需要删除的key发送至消息队列；
4. 自己消费消息，获得需要删除的key；
5. 继续重试删除操作，直到成功；

然而，该方案有一个缺点，对业务线代码造成大量的侵入。

方案二
1. 更新数据库数据；
2. 数据库会将操作信息写入binlog日志当中；
3. 订阅程序提取出所需要的数据以及key；
4. 另起一段非业务代码，获得该信息；
5. 将这些信息发送至消息队列；
6. 重新从消息队列中获得该数据，重试操作；

**上述的订阅binlog程序在mysql中有现成的中间件叫canal**，可以完成订阅binlog日志的功能。另外，重试机制，博主是采用的是消息队列的方式。如果对一致性要求不是很高，直接在程序中另起一个线程，每隔一段时间去重试即可。

## 三、总结
* 延时双删不能完全保证一致性。无锁方案只能在保证并发前提下尽可能减少不一致的可能，**这也是CAP模式下BASE的一种技术。**
* 要完全保证db与redis一致性，要采用分布式锁的方式(将访问操作串行化)，牺牲一段时间内的可用性来保证多个系统之间数据一致性。所以并发性能会降低。



